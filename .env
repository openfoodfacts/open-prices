# unify separator with windows style
COMPOSE_PATH_SEPARATOR=;
# dev is default target
COMPOSE_FILE=docker-compose.yml;docker/dev.yml

# for dev only: connection to local product opener network and for Product Opener redis
# in staging
COMMON_NET_NAME=po_default

SECRET_KEY=key

DEBUG=True

# Set to True if you want to run Django Q2 tasks in sync mode
# This is useful for local development, but should be set to False in production
Q2_SYNC=False

# Number of Q2 workers to run
Q2_WORKERS = 8

TAG=latest

ALLOWED_HOSTS=localhost,127.0.0.1

CSRF_TRUSTED_ORIGINS=http://127.0.0.1:8000

API_PORT=127.0.0.1:8000

# authentication server
OAUTH2_SERVER_URL=https://world.openfoodfacts.org/cgi/auth.pl

# by default on dev desktop, no restart
RESTART_POLICY=no

# Sentry DNS for bug tracking, used only in staging and production
SENTRY_DNS=

# Log level to use, DEBUG by default in dev
LOG_LEVEL=DEBUG

# Postgres database
POSTGRES_DB=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
# Host is postgres, as we're using docker and the service name is "postgres"
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

POSTGRES_EXPOSE=127.0.0.1:5432

ENVIRONMENT=net

GUNICORN_WORKERS=1

# We use special `host.docker.internal` to access the localhost (=your laptop) from
# the docker container
# It works because we added the special `host.docker.internal:host-gateway`
# host in dev.yml for all services
# Triton is the ML inference server used at Open Food Facts
TRITON_URI=host.docker.internal:5504

# By default, don't enable ML predictions, as we don't necessarily have a Triton
# server running.
# During local development, to enable ML predictions, set this to True and make sure
# you have Triton running on port 5504.
ENABLE_ML_PREDICTIONS=False

# If you want to enable listening for Redis updates, set this to True
ENABLE_REDIS_UPDATES=False

# Google specific configuration for Gemini AI.
# Gemini can use Vertex AI or Gemini API, we force it to use Vertex AI.
# In production as it allows us to set the location
# For local development, we can use the Gemini API as it is easier to set up.
GOOGLE_GENAI_USE_VERTEXAI=False
# Force location to be Paris (only if using Vertex AI)
GOOGLE_CLOUD_LOCATION=europe-west9

# For local development, set up your API key here
GEMINI_API_KEY=

# Whether we send requests to Gemini in parallel using asyncio or not
# for price tag extraction.
PRICE_TAG_EXTRACTION_ASYNC_REQUESTS=False
